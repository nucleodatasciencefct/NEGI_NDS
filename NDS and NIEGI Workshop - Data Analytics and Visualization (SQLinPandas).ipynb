{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working SQL files with Pandas - Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](pandas_logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Pandas library allows extensive applicability of functions when talking about data. With Pandas, analyzing data has become an easier task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We first need to export the necessary librarys in Python format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In this situation, as part of this workshop, we will open a file in SQLite format. It is possible to open in other formats and with other methods. An auxiliary library (sqlite3) will be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_ = '' # Set file directory\n",
    "\n",
    "connection_data = sqlite3.connect(dir_) \n",
    "\n",
    "\n",
    "query = '' # Which query allows you to select all data\n",
    "\n",
    "data_to_df = pd.read_sql_query(query, connection_data) # Keep them in a Pandas Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Another useful tool can be merging and joining operations\n",
    "\n",
    "\n",
    "![](join-types-merge-names.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lets take a previous look at our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For inner join\n",
    "\n",
    "inner_data = pd.merge(, , how='inner', on='')\n",
    "\n",
    "inner_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Equivalent SQL query\n",
    "\n",
    "SELECT *\n",
    "\n",
    "FROM \n",
    "\n",
    "JOIN  ON . = .;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For left join\n",
    "\n",
    "left_data = pd.merge(, , how='', on='')\n",
    "\n",
    "left_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Equivalent SQL query\n",
    "\n",
    "SELECT *\n",
    "\n",
    "FROM \n",
    "\n",
    "LEFT JOIN  ON . = .;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For right join\n",
    "\n",
    "right_data = pd.merge(, , how='', on='')\n",
    "\n",
    "right_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Equivalent SQL query\n",
    "\n",
    "SELECT *\n",
    "\n",
    "FROM \n",
    "\n",
    "RIGHT JOIN  ON . = .;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Full Outer Join\n",
    "\n",
    "full_data = pd.merge(, , how='', on='')\n",
    "\n",
    "full_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Equivalent SQL query\n",
    "\n",
    "\n",
    "SELECT *\n",
    "\n",
    "FROM \n",
    "\n",
    "OUTER JOIN  ON . = . ;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### You can also subselect with Dataframe and convert the new table to sqlite format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_name_file = ''\n",
    "\n",
    "\n",
    "indexed_data = data_to_df[data_to_df.column_name == value]\n",
    "\n",
    "\n",
    "indexed_data.to_sql(new_name_file, con, if_exists=\"replace\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We can also limit the view of our dataset with the .set_option method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 30000)\n",
    "pd.set_option('display.max_columns', 5000)\n",
    "pd.set_option('display.width', 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_df.head() # Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_to_df) # Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_df.dtype() # Data types available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lets do some indexing of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = ''\n",
    "\n",
    "\n",
    "info = data_to_df[column_name] # check values of a certain column\n",
    "\n",
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['', '']\n",
    "\n",
    "infos = data_to_df[column_names] # check values of multiple columns\n",
    "\n",
    "infos "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The [] provides the following convenience shortcuts:\n",
    "\n",
    "##### Series: selecting a label: s[label]\n",
    "##### DataFrame: selecting a single or multiple columns: df['col'] or df[['col1', 'col2']]\n",
    "##### Slicing the rows: df['row_label1':'row_label2'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Some methods allow us for advanced methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loc: selection by label;\n",
    "\n",
    "iloc: selection by position;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_df.iloc[0] # first row of data frame \n",
    "data_to_df.iloc[1] # second row of data frame \n",
    "data_to_df.iloc[-1] # last row of data frame \n",
    "\n",
    "data_to_df.iloc[:,0] # first column of data frame \n",
    "data_to_df.iloc[:,1] # second column of data frame \n",
    "data_to_df.iloc[:,-1] # last column of data frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_df.iloc[0:5] # first five rows of dataframe\n",
    "data_to_df.iloc[:, 0:2] # first two columns of data frame with all rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Selections using the loc method are based on the index of the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_column = ''\n",
    "\n",
    "data_to_df.set_index(index_column, inplace=True)\n",
    "data_to_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### With boolean indexing selection, you pass an array or Series of True/False values to the .loc in order to select the rows where your Series has True values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In case you want to modify certain values, you can use .loc method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### It is also possible to apply the same function on subsets of your dataframe, based on some keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_column = ''\n",
    "\n",
    "data_to_df.groupby(chosen_column).aggregate(np.sum)\n",
    "\n",
    "data_to_df.groupby(chosen_column).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Finally, we need to close the SQL session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
